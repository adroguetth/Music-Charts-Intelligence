name: Download YouTube Chart (Weekly SQLite)

on:
  schedule:
    - cron: '0 12 * * 1'  # Cada lunes a las 12:00 UTC
  workflow_dispatch:       # EjecuciÃ³n manual
  push:
    branches:
      - main
    paths:
      - 'scripts/*.py'

env:
  RETENTION_DAYS: 30

jobs:
  download-and-store:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    permissions:
      contents: write
    
    steps:
    # 1. Checkout del repositorio
    - name: ðŸ“š Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
    
    # 2. Configurar Python
    - name: ðŸ Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: "3.12"
        cache: 'pip'
    
    # 3. Instalar dependencias
    - name: ðŸ“¦ Install dependencies
      run: |
        pip install -r requirements.txt
        python -m playwright install chromium
        python -m playwright install-deps
    
    # 4. Crear estructura de directorios
    - name: ðŸ“ Create directory structure
      run: |
        mkdir -p data charts_archive/databases charts_archive/backups
    
    # 5. Ejecutar script de descarga
    - name: ðŸš€ Run download script
      run: |
        python scripts/1_descargar.py
      env:
        GITHUB_ACTIONS: true
    
    # 6. Verificar resultados
    - name: âœ… Verify results
      run: |
        echo "ðŸ“Š Verificando resultados..."
        
        echo "ðŸ“ Contenido de charts_archive/:"
        ls -lah charts_archive/
        
        echo -e "\nðŸ—ƒï¸ Bases de datos semanales:"
        ls -lah charts_archive/databases/*.db 2>/dev/null || echo "No hay bases de datos"
        
        echo -e "\nðŸ’¾ Backups:"
        ls -lah charts_archive/backups/*.db 2>/dev/null || echo "No hay backups"
        
        echo -e "\nðŸ“Š CSV mÃ¡s reciente:"
        ls -lah charts_archive/latest_chart.csv 2>/dev/null || echo "No hay CSV"
        
        echo -e "\nðŸ“ˆ EstadÃ­sticas de archivos:"
        find charts_archive -type f -exec ls -lh {} \; | awk '{print $5, $9}'
    
    # 7. Commit y push de cambios
    - name: ðŸ“¤ Commit and push changes
      run: |
        echo "ðŸ“ Preparando commit..."
        
        git config --global user.name "github-actions[bot]"
        git config --global user.email "github-actions[bot]@users.noreply.github.com"
        
        # Agregar solo archivos de archivado
        git add charts_archive/
        
        if git diff --cached --quiet; then
          echo "ðŸ“­ No hay cambios para commit"
        else
          DATE=$(date +'%Y-%m-%d')
          WEEK=$(date +'%Y-W%W')
          git commit -m "ðŸ“Š YouTube Chart Update ${DATE} (Week ${WEEK}) [Automated]"
          
          echo "â¬†ï¸ Subiendo cambios..."
          git push origin HEAD:main
          echo "âœ… Cambios subidos al repositorio"
        fi
    
    # 8. Subir artifacts para debugging (solo si hay error)
    - name: ðŸ“¦ Upload artifacts (on failure)
      if: failure()
      uses: actions/upload-artifact@v4
      with:
        name: chart-debug-${{ github.run_number }}
        path: |
          data/
          charts_archive/
        retention-days: 7
    
    # 9. Reporte final
    - name: ðŸ“‹ Final report
      if: always()
      run: |
        echo "========================================"
        echo "ðŸŽµ REPORTE FINAL DE EJECUCIÃ“N"
        echo "========================================"
        echo "ðŸ“… Fecha: $(date)"
        echo "ðŸ“Œ Trigger: ${{ github.event_name }}"
        echo "ðŸ”— Commit: ${{ github.sha }}"
        echo ""
        
        WEEK_ID=$(python3 -c "from datetime import datetime; y,w,_ = datetime.now().isocalendar(); print(f'{y}-W{w:02d}')")
        DB_FILE="charts_archive/databases/youtube_charts_${WEEK_ID}.db"
        
        if [ -f "$DB_FILE" ]; then
          echo "âœ… Base de datos de la semana actualizada: $DB_FILE"
          SIZE=$(stat -f%z "$DB_FILE" 2>/dev/null || stat -c%s "$DB_FILE")
          echo "ðŸ“Š TamaÃ±o: $((SIZE / 1024)) KB"
        else
          echo "âš ï¸ Base de datos de la semana no encontrada"
        fi
        
        if [ -f "charts_archive/latest_chart.csv" ]; then
          echo "âœ… CSV mÃ¡s reciente actualizado"
          LATEST_SIZE=$(stat -f%z "charts_archive/latest_chart.csv" 2>/dev/null || stat -c%s "charts_archive/latest_chart.csv")
          echo "ðŸ“Š TamaÃ±o: $((LATEST_SIZE / 1024)) KB"
        fi
        
        TOTAL_DBS=$(find charts_archive/databases -name "youtube_charts_*.db" 2>/dev/null | wc -l)
        if [ "$TOTAL_DBS" -gt 0 ]; then
          echo ""
          echo "ðŸ“¦ Total de bases de datos histÃ³ricas: $TOTAL_DBS"
        fi
        
        TOTAL_BACKUPS=$(find charts_archive/backups -name "backup_*.db" 2>/dev/null | wc -l)
        if [ "$TOTAL_BACKUPS" -gt 0 ]; then
          echo "ðŸ’¾ Total de backups disponibles: $TOTAL_BACKUPS"
        fi
        
        echo ""
        echo "âœ… Proceso completado"
        echo "========================================"
