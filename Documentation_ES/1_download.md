# üéµ YouTube Charts Scraper - Script 1: Descarga Automatizada

![Texto alternativo](https://img.shields.io/badge/License-MIT-green) ![Texto alternativo](https://img.shields.io/badge/Web-Scraping-orange) [![Python](https://img.shields.io/badge/Python-3776AB?logo=python&logoColor=fff)](#) [![Pandas](https://img.shields.io/badge/Pandas-150458?logo=pandas&logoColor=fff)](#) [![NumPy](https://img.shields.io/badge/NumPy-4DABCF?logo=numpy&logoColor=fff)](#) [![Playwright](https://custom-icon-badges.demolab.com/badge/Playwright-2EAD33?logo=playwright&logoColor=fff)](#) [![SQLite](https://img.shields.io/badge/SQLite-%2307405e.svg?logo=sqlite&logoColor=white)](#)


## üìã Descripci√≥n General

Este proyecto consiste en un sistema automatizado para la descarga y almacenamiento semanal de las listas m√°s populares de YouTube. El script `1_download.py` es el primer componente de una serie de herramientas dise√±adas para extraer, procesar y analizar datos de YouTube Charts.

### Caracter√≠sticas Principales

- **Descarga Completa**: Obtiene listas completas de 100 canciones
- **Automatizaci√≥n**: Programaci√≥n semanal mediante GitHub Actions
- **Almacenamiento Hist√≥rico**: Base de datos SQLite con versionado por semana
- **Sistema de Respaldo**: Backups autom√°ticos antes de actualizaciones
- **Robustez**: M√∫ltiples estrategias de detecci√≥n y modo de respaldo
- **Optimizaci√≥n CI/CD**: Configurado espec√≠ficamente para GitHub Actions



## üõ†Ô∏è Stack Tecnol√≥gico

### **Tecnolog√≠as Principales**

| Componente | Tecnolog√≠a | Prop√≥sito |
|-----------|-----------|---------|
| **Lenguaje** | Python 3.12+ | Lenguaje principal de desarrollo |
| **Automatizaci√≥n Web** | Playwright | Automatizaci√≥n de navegador para scraping |
| **Procesamiento de Datos** | Pandas | Manipulaci√≥n y an√°lisis de CSV |
| **Base de Datos** | SQLite3 | Persistencia local de datos |
| **CI/CD** | GitHub Actions | Ejecuci√≥n semanal automatizada |

### **Arquitectura del Proyecto**

Este script es parte de un pipeline multi-etapa:

1. **Etapa 1 (Actual)**: `1_download.py` - Extracci√≥n de datos brutos
2. **Etapa 2 (Futura)**: `2_enrich.py` - Enriquecimiento y procesamiento de datos
3. **Etapa 3+**: Herramientas adicionales de an√°lisis y visualizaci√≥n

### **Flujo General de Datos**

<img src="https://drive.google.com/uc?export=view&id=1iwi96GAMQXgi42aesPn755vN_VRJYx8D"
  width="700"
     alt="Flujo General de Datos">

## üìä Diagrama de Flujo del Proceso

<img src="https://drive.google.com/uc?export=view&id=1fA6bXnQeZ0vKXHobH65cKFmm251QRJnu" 
     width="400" 
     alt="Diagrama de Flujo del Proceso">

## üîç An√°lisis Detallado de `1_download.py`

### Estructura del C√≥digo

#### **1. Configuraci√≥n Inicial y Directorios**

```python
# Directorios principales
OUTPUT_DIR = Path("data")
ARCHIVE_DIR = Path("charts_archive/1_download-chart")
DATABASE_DIR = ARCHIVE_DIR / "databases"
BACKUP_DIR = ARCHIVE_DIR / "backup"
```

El script organiza los datos en una estructura jer√°rquica:

- `data/`: Datos temporales y de depuraci√≥n
- `charts_archive/1_download-chart/`: Archivo principal de datos descargados
  - `databases/`: Bases de datos SQLite por semana
  - `backup/`: Copias de respaldo temporales
  - `latest_chart.csv`: Datos del chart m√°s reciente

#### **2. Detecci√≥n de Entorno**

```python
IS_GITHUB_ACTIONS = os.getenv('GITHUB_ACTIONS') == 'true'
```

El script detecta autom√°ticamente si se ejecuta en GitHub Actions y ajusta:

- Tiempos de espera m√°s largos
- Registros detallados para CI/CD
- Estrategias de recuperaci√≥n espec√≠ficas

#### **3. Sistema de Instalaci√≥n de Dependencias**

```python
def install_playwright():
    """Verificaci√≥n e instalaci√≥n completa de Playwright"""
```

Esta funci√≥n realiza una verificaci√≥n de tres niveles:

1. Paquete Python de Playwright
2. Binarios del navegador Chromium
3. Dependencias del sistema operativo

<div style="page-break-after: always;"></div>

#### **4. Estrategias de Web Scraping**

El script implementa m√∫ltiples enfoques para localizar el bot√≥n de descarga:

```python
# 1. Selector primario por ID
download_button = await page.query_selector('#download-button')

# 2. Selector por aria-label (respaldo 1)
download_button = await page.query_selector('[aria-label*="Download"]')

# 3. Selector por texto (respaldo 2)
download_button = await page.query_selector('text=Download')
```

**Caracter√≠sticas anti-detecci√≥n:**

- User agent personalizado
- Inyecci√≥n de JavaScript para ocultar automatizaci√≥n
- Configuraci√≥n realista de vista y localizaci√≥n
- Encabezados HTTP personalizados



#### **5. Gesti√≥n de Base de Datos SQLite**

```python
def update_sqlite_database(csv_path: Path, week_id: str):
```

**Proceso de actualizaci√≥n:**

1. Crear respaldo de la base de datos existente
2. Leer y validar el CSV descargado
3. Agregar metadatos (fecha, semana, timestamp)
4. Usar patr√≥n de tabla temporal para evitar p√©rdida de datos
5. Crear √≠ndices optimizados
6. Actualizar estad√≠sticas

**Estructura de la tabla `chart_data`:**

| Columna            | Tipo      | Descripci√≥n             |
| ------------------ | --------- | ----------------------- |
| Rank               | `INTEGER` | Posici√≥n en el chart    |
| Previous Rank      | `INTEGER` | Posici√≥n anterior       |
| Track Name         | `TEXT`    | Nombre de la canci√≥n    |
| Artist Names       | `TEXT`    | Artista(s)              |
| Periods on Chart   | `INTEGER` | Semanas en el chart     |
| Views              | `INTEGER` | N√∫mero de vistas        |
| Growth             | `TEXT`    | Porcentaje de crecimiento |
| YouTube URL        | `TEXT`    | Enlace al video         |
| download_date      | `TEXT`    | Fecha de descarga       |
| download_timestamp | `TEXT`    | Timestamp completo      |
| week_id            | `TEXT`    | Identificador de semana |

#### **6. Sistema de Respaldo y Limpieza**

**Respaldos temporales:**

- Creados antes de cada actualizaci√≥n
- Nomenclatura: `backup_YYYY-WXX_YYYYMMDD_HHMMSS.db`
- Retenci√≥n: 7 d√≠as por defecto

**Limpieza de bases de datos antiguas:**

- Retenci√≥n configurable (52 semanas por defecto)
- Eliminaci√≥n basada en fecha del nombre de archivo
- Estad√≠sticas de limpieza en registros

#### **7. Modo de Respaldo**

Cuando el scraping no est√° disponible:

```python
def create_fallback_file():
    """Genera datos de muestra con estructura realista"""
```

- 100 registros simulados

- Estructura id√©ntica al CSV real

- Metadatos consistentes

- Para desarrollo y recuperaci√≥n de errores

  <div style="page-break-after: always;"></div>

#### **8. Reportes y Estad√≠sticas**

```python
def list_available_databases():
    """Muestra estad√≠sticas de todas las bases de datos"""
```

Incluye:

- N√∫mero total de bases de datos
- Registros por base de datos
- Rango de fechas cubierto
- Tama√±os de archivo
- Total de registros acumulados



## ‚öôÔ∏è An√°lisis del Workflow de GitHub Actions (`1_download-chart.yml`)

### **Estructura del Workflow**

```yaml
name: Download YouTube Chart
on:
  schedule:
    - cron: '0 12 * * 1'  # Lunes 12:00 UTC
  workflow_dispatch:       # Ejecuci√≥n manual
  push:                    # Disparador en cambios
```

### **Jobs y Pasos**

#### **Job: `download-and-store`**

- **Sistema operativo**: Ubuntu Latest
- **Timeout**: 30 minutos
- **Permisos**: Acceso de escritura al repositorio

#### **Pasos Detallados:**

**1. üìö Checkout del Repositorio**

```yaml
uses: actions/checkout@v4
with:
  fetch-depth: 0  # Historial completo para operaciones git
```

<div style="page-break-after: always;"></div>

**2. üêç Configuraci√≥n de Python 3.12**

```yaml
uses: actions/setup-python@v5
with:
  cache: 'pip'  # Cach√© de dependencias
```

**3. üì¶ Instalaci√≥n de Dependencias**
   - Playwright y navegador Chromium
   - Pandas, NumPy para procesamiento
   - Dependencias del sistema

**4. üìÅ Creaci√≥n de Estructura de Directorios**

```yaml
run: |
  mkdir -p data charts_archive/1_download-chart/databases charts_archive/1_download-chart/backup
```

**5. üöÄ Ejecuci√≥n del Script Principal**

```yaml
run: |
  python scripts/1_download.py
env:
  GITHUB_ACTIONS: true  # Variable de entorno para detecci√≥n
```

**6. ‚úÖ Verificaci√≥n de Resultados**
   - Listado de archivos generados en `charts_archive/1_download-chart/`
   - Estad√≠sticas de tama√±o
   - Validaci√≥n de existencia

**7. üì§ Commit y Push Autom√°tico**
   - Configuraci√≥n autom√°tica de usuario
   - Solo hace commit de cambios en `charts_archive/`
   - Mensaje con fecha y semana
   - Push autom√°tico a main

**8. üì¶ Subida de Artefactos (solo en fallo)**
   - Datos y archivos para depuraci√≥n
   - Retenci√≥n: 7 d√≠as

**9. üìã Reporte Final**
   - Estad√≠sticas detalladas
   - Informaci√≥n del disparador
   - Tama√±os de archivo
   - Conteo de bases de datos

### **Programaci√≥n Cron**

```cron
'0 12 * * 1'  # Minuto 0, Hora 12, Cualquier d√≠a del mes, Cualquier mes, Lunes
```

- **Ejecuci√≥n**: Todos los lunes a las 12:00 UTC
- **Equivalente**: 13:00 CET (Hora Central Europea)
- **Consideraciones**: YouTube actualiza los charts los domingos/lunes



## üöÄ Instalaci√≥n y Configuraci√≥n Local

### **Requisitos Previos**

- Python 3.7 o superior
- Git instalado
- Acceso a internet para descargas

### **Instalaci√≥n Paso a Paso**

**1. Clonar el Repositorio**

```bash
git clone <url-del-repositorio>
cd <directorio-del-proyecto>
```

**2. Crear Entorno Virtual (recomendado)**

```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

**3. Instalar Dependencias**

```bash
pip install -r requirements.txt

# Instalar navegador Playwright
python -m playwright install chromium

# Instalar dependencias del sistema (Linux)
python -m playwright install-deps
```

**4. Ejecutar Prueba Inicial**

```bash
python scripts/1_download.py
```

### **Configuraci√≥n para Desarrollo**

**Variables de Entorno Opcionales**

```bash
# Para simular entorno de GitHub Actions
export GITHUB_ACTIONS=true

# Para depuraci√≥n detallada
export PWDEBUG=1
```

**Ejecuci√≥n con Visualizaci√≥n**

```python
# Modificar en el script:
headless=False  # En lugar de True
```



## üìÅ Estructura de Archivos Generados

```text
charts_archive/
‚îú‚îÄ‚îÄ 1_download-chart/
‚îÇ   ‚îú‚îÄ‚îÄ latest_chart.csv              # CSV m√°s reciente (siempre actualizado)
‚îÇ   ‚îú‚îÄ‚îÄ databases/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ youtube_charts_2025-W01.db
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ youtube_charts_2025-W02.db
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ... (una por semana)
‚îÇ   ‚îî‚îÄ‚îÄ backup/
‚îÇ       ‚îú‚îÄ‚îÄ backup_2025-W01_20250106_120500.db
‚îÇ       ‚îî‚îÄ‚îÄ ... (respaldos temporales)
‚îî‚îÄ‚îÄ 2_enriched_chart/
    ‚îî‚îÄ‚îÄ (datos enriquecidos futuros)
```

### **Convenci√≥n de Nomenclatura**

- **Bases de datos**: `youtube_charts_YYYY-WXX.db`
- **Respaldos**: `backup_YYYY-WXX_YYYYMMDD_HHMMSS.db`
- **CSV semanal**: `latest_chart.csv` (siempre sobrescrito)

<div style="page-break-after: always;"></div>

## üîß Personalizaci√≥n y Configuraci√≥n

### **Par√°metros Ajustables en el Script**

```python
# En 1_download.py
RETENTION_DAYS = 7      # D√≠as para mantener respaldos
RETENTION_WEEKS = 52    # Semanas para mantener bases de datos
TIMEOUT = 120000        # Timeout en milisegundos (2 minutos)
```

### **Configuraci√≥n del Workflow**

```yaml
# En 1_download-chart.yml
env:
  RETENTION_DAYS: 30    # D√≠as para artefactos

timeout-minutes: 30     # Timeout total del job
```



## üêõ Soluci√≥n de Problemas

### **Problemas Comunes y Soluciones**

**1. Error: "Playwright browsers not installed"**

```bash
# Soluci√≥n manual
python -m playwright install chromium
python -m playwright install-deps
```

**2. Error: Timeout en GitHub Actions**
   - Verificar conexi√≥n de red del runner
   - Aumentar timeout en YML
   - Revisar registros de Playwright

**3. Error: Bot√≥n de descarga no encontrado**
   - YouTube puede haber cambiado la interfaz
   - Revisar captura de pantalla en artefactos
   - Actualizar selectores en el c√≥digo

**4. Error: Base de datos corrupta**
   - Usar respaldos autom√°ticos
   - Verificar permisos de escritura
   - Revisar espacio en disco

### **Registros y Depuraci√≥n**

**Niveles de registro disponibles:**

1. **Informaci√≥n b√°sica**: Ejecuci√≥n normal
2. **Debug de GitHub Actions**: Con `GITHUB_ACTIONS=true`
3. **Captura de pantalla de error**: En artefactos al fallar
4. **Estad√≠sticas detalladas**: Reporte final



## üìà Monitoreo y Mantenimiento

### **Indicadores de Salud**

1. **Tama√±o de base de datos**: Crece ~100 registros/semana
2. **Tama√±o del CSV**: ~10-50KB por archivo
3. **Tiempo de ejecuci√≥n**: 2-5 minutos normalmente
4. **Tasa de √©xito**: Deber√≠a ser >95% en condiciones normales

### **Alertas Recomendadas**

1. **Fallo consecutivo**: 2 o m√°s fallos consecutivos
2. **Tiempo excesivo**: >10 minutos de ejecuci√≥n
3. **Datos incompletos**: <100 registros en CSV
4. **Espacio en disco**: >1GB en `charts_archive/`



## üìÑ Licencia y Atribuci√≥n

- **Licencia**: MIT

- **Autor**: Alfonso Droguett
  - üîó **LinkedIn:** [Alfonso Droguett](https://www.linkedin.com/in/adroguetth/)
  - üåê **Portafolio web:** [adroguett-portfolio.cl](https://www.adroguett-portfolio.cl/)
  - üìß **Email:** [adroguett.consultor@gmail.com](mailto:adroguett.consultor@gmail.com)

- **Dependencias**:
  - Playwright (Apache 2.0)
  - Pandas (BSD 3-Clause)
  - NumPy (BSD)

  <div style="page-break-after: always;"></div>

## ü§ù Contribuci√≥n

1. Reportar problemas con registros completos
2. Proponer mejoras con casos de uso
3. Mantener compatibilidad con la estructura existente
4. Documentar cambios en el README

---

**Nota**: Este Documentacion corresponde espec√≠ficamente al script `1_download.py`. Para documentaci√≥n de otros scripts, consultar sus READMEs respectivos.
